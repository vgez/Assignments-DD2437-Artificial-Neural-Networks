# DD2437 Artificial Neural Networks and Deep Architectures - Group Assignments

Complete assignment coursework for **DD2437** at KTH Royal Institute of Technology. The labs focused on the implementation and experimentation of a variety of network architectures such as the _Multilayer Perceptron_, _Self-organising Maps_, _Hopfield Networks_, _Restricted Boltzmann Machines_ and _Deep Belief Nets_. Most networks were implemented from scratch in _Python3_ using _NumPy_. A large amount of experiments were performed across the assignments. _Classification_ and _regression_ tasks both _supervised_ and _unsupervised_.

## Team Members

<ul>
    <li>
        <strong>Valdemar Gezelius</strong>
    </li>  
    <li>
        <strong>Maximilian Auer</strong>
    </li>
    <li>
        <strong>Lukas Fr√∂sslund</strong>
    </li>
</ul>

## Technologies

-   [Python3](https://www.python.org/)
-   [NumPy](https://numpy.org/)

## Assignment Details

### Assignment 1

This assignment focused on _feed-forward architectures_ and the _backpropagation algorithm_. Both classification and regression tasks were performed.

### Assignment 2

In this assignment, the focus was on _RBF-networks_, Self-organising Maps and _Competitive Learning_, using non-labeled real-world data to perform unsupervised tasks.

### Assignment 3

Here the focus was on Hopfield Networks. Many aspects of the Hopfield Network were experimented with, such as the _Energy function_, _sparse patterns_ and _distortion resistance_.

### Assignment 4

In this assignment focus was on _deep neural networks_, specifically Restricted Boltzmann Machines (RBMs) and Deep Belief Nets (DBNs). Image recognition tasks were performed on both architectures. _Greedy layer-wise pretraining_ was explored on the DBNs, consisting of stacked RBM architectures. The generation task was also explored using _Gibbs sampling_.

More details available in the <a href="https://github.com/vgez/Assignments-DD2437-Artificial-Neural-Networks/tree/main/Assignment%20Reports">assignment reports</a>.
